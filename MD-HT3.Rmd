---
title: "MD-HT3"
author: "Diego-Fabian"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Análisis exploratorio 

```{r train}
library(dplyr)
if (!requireNamespace("Hmisc", quietly = TRUE)) {
  install.packages("Hmisc")
}
library(Hmisc)
datos  <- read.csv("train.csv")
```


```{r }
datos  <- read.csv("train.csv")
# Crear un dataframe con las variables, descripciones y tipos de variable
# Extraer los nombres de las variables
variables <- colnames(datos)
descripcion <- c("Identificador unico","Identifica el tipo de vivienda implicada en la venta.", "Identifica la clasificación general de zonificación de la venta.", "Pies lineales de la calle conectada a la propiedad.", "Tamaño del lote en pies cuadrados", "Tipo de calle de acceso a la propiedad", "Tipo de callejón de acceso a la propiedad", "Forma general de la propiedad", "Planitud de la propiedad", "Tipo de servicios disponibles", "Configuración de la parcela", "Pendiente de la propiedad", "Ubicaciones físicas dentro de los límites de la ciudad de Ames", "Proximidad a varias condiciones", "Proximidad a varias condiciones (si hay más de una)", "Tipo de vivienda", "Estilo de la vivienda", "Califica el material y el acabado general de la vivienda", "Valora el estado general de la vivienda", "Fecha de construcción original", "Fecha de remodelación (la misma que la fecha de construcción si no hay remodelaciones ni ampliaciones)", "Tipo de tejado", "Material del tejado", "Revestimiento exterior de la casa", "Revestimiento exterior de la casa (si hay más de un material)", "Tipo de revestimiento de mampostería", "Área de revestimiento de mampostería en pies cuadrados", "Evalúa la calidad del material en el exterior", "Evalúa el estado actual del material en el exterior", "Tipo de cimentación", "Evalúa la altura del sótano", "Evalúa el estado general del sótano", "Se refiere a las paredes de la planta baja o del jardín", "Calificación de la superficie acabada del sótano", "Pies cuadrados acabados tipo 1", "Calificación de la superficie acabada del sótano (si hay varios tipos)", "Pies cuadrados acabados de tipo 2", "Pies cuadrados sin terminar de la superficie del sótano", "Total de pies cuadrados de superficie del sótano", "Tipo de calefacción", "Calidad y estado de la calefacción", "Aire acondicionado central", "Sistema eléctrico", "Pies cuadrados del primer piso", "Pies cuadrados del segundo piso", "Pies cuadrados acabados de baja calidad (todas las plantas)", "Superficie habitable por encima del nivel del suelo en pies cuadrados", "Baños completos del sótano", "Sótano medio baño", "Baños completos sobre rasante", "Medios baños por encima del grado", "Dormitorios sobre rasante (NO incluye dormitorios en sótano)", "Cocinas sobre rasante", "Calidad de la cocina", "Total de habitaciones sobre rasante (no incluye baños)", "Funcionalidad de la vivienda (se asume como típica a menos que se justifiquen deducciones)", "Número de chimeneas", "Calidad de la chimenea", "Ubicación del garaje", "Año de construcción del garaje", "Acabado interior del garaje", "Tamaño del garaje en capacidad de coches", "Tamaño del garaje en metros cuadrados", "Calidad del garaje", "Estado del garaje", "Calzada pavimentada", "Superficie de cubierta de madera en pies cuadrados", "Superficie de porche abierto en pies cuadrados", "Superficie del porche cerrado en metros cuadrados", "Superficie del porche para tres estaciones en metros cuadrados", "Screen porch área en pies cuadrados", "Superficie de la piscina en metros cuadrados", "Calidad de la piscina", "Calidad de la valla", "Característica miscelánea no incluida en otras categorías", "Valor de la característica miscelánea", "Mes vendido (MM)", "Año de venta (AAAA)", "Tipo de venta", "Condición de venta", "Precio venta")

tipos_variables <- c("numérica", "categórica", "categórica", "numérica", "numérica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "numérica", "numérica", "numérica", "numérica", "categórica", "categórica", "categórica", "categórica", "categórica", "numérica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "categórica", "numérica", "categórica", "numérica", "numérica", "numérica", "categórica", "categórica", "categórica", "categórica", "numérica", "numérica", "numérica", "numérica", "numérica", "numérica", "numérica", "numérica", "numérica", "numérica", "categórica", "numérica", "categórica", "numérica", "categórica", "categórica", "numérica", "categórica", "numérica", "numérica", "categórica", "categórica", "categórica", "numérica", "numérica", "numérica", "numérica", "numérica", "numérica", "categórica", "categórica", "categórica", "numérica", "numérica", "numérica", "categórica", "categórica", "numérica")

# Crear el dataframe con la información
tabla_variables <- data.frame(Variable = variables,
                              Descripción = descripcion,
                              Tipo = tipos_variables )

print(tabla_variables)
```



```{r train}

# Campos donde se mide por calificaciones:
#       Ex	Excellent
#       Gd	Good
#       TA	Typical/Average
#       Fa	Fair
#       Po	Poor
#       NA	No

columnas_calificaciones <- c("Id", "ExterQual", "ExterCond", "Foundation", "BsmtQual", "BsmtCond", "HeatingQC", "KitchenQual", "FireplaceQu", "GarageQual", "GarageCond", "PoolQC")

datos_procesados_calificaciones <- datos[, columnas_calificaciones]

print(datos_procesados_calificaciones)


```

``` {r mapeo}
datos <- datos %>%
  mutate(ExterCond = case_when(
    ExterCond == "Ex" ~ 5,
    ExterCond == "Gd" ~ 4,
    ExterCond == "TA" ~ 3,
    ExterCond == "Fa" ~ 2,
    ExterCond == "Po" ~ 1,
    TRUE ~ 0
  )) %>%
    mutate(ExterQual = case_when(
    ExterQual == "Ex" ~ 5,
    ExterQual == "Gd" ~ 4,
    ExterQual == "TA" ~ 3,
    ExterQual == "Fa" ~ 2,
    ExterQual == "Po" ~ 1,
    TRUE ~ 0
  )) %>%
  mutate(Foundation = case_when(
    Foundation == "BrkTil" ~ 6,
    Foundation == "CBlock" ~ 5,
    Foundation == "PConc" ~ 4,
    Foundation == "Slab" ~ 3,
    Foundation == "Stone" ~ 2,
    Foundation == "Wood" ~ 1,
    TRUE ~ NA_real_
  )) %>%
  mutate(BsmtQual = case_when(
    BsmtQual == "Ex" ~ 5,
    BsmtQual == "Gd" ~ 4,
    BsmtQual == "TA" ~ 3,
    BsmtQual == "Fa" ~ 2,
    BsmtQual == "Po" ~ 1,
    TRUE ~ 0
  ))%>%
  mutate(BsmtCond = case_when(
    BsmtCond == "Ex" ~ 5,
    BsmtCond == "Gd" ~ 4,
    BsmtCond == "TA" ~ 3,
    BsmtCond == "Fa" ~ 2,
    BsmtCond == "Po" ~ 1,
    TRUE ~ 0
  ))%>%
    mutate(BsmtExposure = case_when(
    BsmtExposure == "Ex" ~ 5,
    BsmtExposure == "Gd" ~ 4,
    BsmtExposure == "TA" ~ 3,
    BsmtExposure == "Fa" ~ 2,
    BsmtExposure == "Po" ~ 1,
    TRUE ~ 0
  ))%>%
    mutate(Heating = case_when(
    Heating == "Floor" ~ 6,
    Heating == "GasA" ~ 5,
    Heating == "GasW" ~ 4,
    Heating == "Grav" ~ 3,
    Heating == "OthW" ~ 2,
    Heating == "Wall" ~ 1,
    TRUE ~ 0
  ))%>%
   mutate(CentralAir = case_when(
    CentralAir == "Y" ~ 1,
    TRUE ~ 0
  ))%>%
   mutate(Heating = case_when(
    Heating == "Floor" ~ 6,
    Heating == "GasA" ~ 5,
    Heating == "GasW" ~ 4,
    Heating == "Grav" ~ 3,
    Heating == "OthW" ~ 2,
    Heating == "Wall" ~ 1,
    TRUE ~ 0
  ))%>%
  mutate(Electrical = case_when(
    Electrical == "SBrkr" ~ 5,
    Electrical == "FuseA" ~ 4,
    Electrical == "FuseF" ~ 3,
    Electrical == "FuseP" ~ 2,
    Electrical == "Mix" ~ 1,
    TRUE ~ 0
  ))%>%
  mutate(KitchenQual = case_when(
    KitchenQual == "Ex" ~ 5,
    KitchenQual == "Gd" ~ 4,
    KitchenQual == "TA" ~ 3,
    KitchenQual == "Fa" ~ 2,
    KitchenQual == "Po" ~ 1,
    TRUE ~ 0
  ))%>%
  mutate(FireplaceQu = case_when(
    FireplaceQu == "Ex" ~ 5,
    FireplaceQu == "Gd" ~ 4,
    FireplaceQu == "TA" ~ 3,
    FireplaceQu == "Fa" ~ 2,
    FireplaceQu == "Po" ~ 1,
    TRUE ~ 0
  ))%>%
  mutate(GarageQual = case_when(
    GarageQual == "Ex" ~ 5,
    GarageQual == "Gd" ~ 4,
    GarageQual == "TA" ~ 3,
    GarageQual == "Fa" ~ 2,
    GarageQual == "Po" ~ 1,
    TRUE ~ 0
  ))%>%
  mutate(GarageCond = case_when(
    GarageCond == "Ex" ~ 5,
    GarageCond == "TA" ~ 3,
    GarageCond == "Fa" ~ 2,
    GarageCond == "Po" ~ 1,
    TRUE ~ 0
  ))%>%
  mutate(PoolQC = case_when(
    PoolQC == "Ex" ~ 5,
    PoolQC == "Gd" ~ 4,
    PoolQC == "TA" ~ 3,
    PoolQC == "Fa" ~ 2,
    PoolQC == "Po" ~ 1,
    TRUE ~ 0
  ))

```


### Verificacion de valores nulos
``` {r correlacion}

# Calcula la suma de valores nulos por columna
nullValues <- sapply(datos, function(x) sum(is.na(x)))

# Filtra las columnas que tienen más de 0 valores nulos
nullValues <- nullValues[nullValues > 0]

# Imprime las columnas con valores nulos y su respectiva cantidad
cat("Columnas con valores NaN:\n")
print(nullValues)

```
Se muestran que los siguientes campos tienen valores nulos, se puede observar que esto es preodminante en: MiscFeature, Fence, Alley. Se debe considerar si estos representan algo de valor o deben ser ignorados en el posterior analisis.


### Correlación y relación
``` {r correlacion}
# Extraemos la columna 'SalePrice' del dataframe
salePriceData <- datos$SalePrice

# Creamos una copia del dataframe excluyendo la columna 'Id' y seleccionando solo las columnas numéricas
datos_numerical_cp <- datos %>%
  dplyr::select(-Id) %>%
  dplyr::select_if(is.numeric)

# Iteramos sobre las columnas del dataframe numérico
for (col in colnames(datos_numerical_cp)) {
  colData <- datos_numerical_cp[[col]]
  
  # Suprimimos los mensajes de advertencia alrededor de cor.test
  corr_test <- suppressWarnings(cor.test(salePriceData, colData, method = "spearman"))
  
  # Extraemos el coeficiente de correlación de Spearman del resultado del test
  corr <- corr_test$estimate
  
  # Verificamos si la correlación es mayor o igual a 0.45
  if (!is.na(corr) && corr >= 0.45) {
    cat(sprintf("'%s' coeficiente de correlación spearman : %f\n", col, corr))
  }
}
```

Se considera unicamente los datos que posean un resultado superior a 0.6 ya que esto nos indica una correlación fuerte. Se utiliza este tipo de relación ya que no poseen una distribución normal como tal.

### 

```{r histograma SalePrice}
hist(datos$SalePrice, main = "Histograma de SalePrice", xlab = "SalePrice", border = "blue", col = "lightblue")
#Diagrama caja y bigotes
boxplot(datos$SalePrice, main = "Boxplot de SalePrice", ylab = "SalePrice", col = "lightblue", border = "blue")

```

```{r histograma LotArea}
hist(datos$LotArea, main = "Histograma de SalePrice", xlab = "LotArea", border = "blue", col = "lightblue")
#Diagrama caja y bigotes
boxplot(datos$LotArea, main = "Boxplot de LotArea", ylab = "LotArea", col = "lightblue", border = "blue")
```

```{r histograma OverallQual}
hist(datos$OverallQual, main = "Histograma de SalePrice", xlab = "OverallQual", border = "blue", col = "lightblue")
#Diagrama caja y bigotes
boxplot(datos$OverallQual, main = "Boxplot de OverallQual", ylab = "OverallQual", col = "lightblue", border = "blue")
```

Como se puede visualizar poseemos datos atípicos muy alejados en el precio de venta, LotArea y overallQual estas graficas se realizaron ya que son de las variables importantes y por eso se relizaron histogramas y caja y bigotes apra visualizar la cantidad de datos atípicos.


###Llenado de data para uso en modelos


```{r na}

# Identificar las columnas numéricas
numeric_features <- sapply(datos, is.numeric)

# Rellenar los valores NAN's con 0 en las columnas numéricas
datos[, numeric_features] <- lapply(datos[, numeric_features, drop = FALSE], function(x) ifelse(is.na(x), 0, x))

#Identificar los nombres de las columnas categóricas
nombres_categoricos <- names(datos)[sapply(datos, function(x) !is.numeric(x))]

#Rellenar los valores NAN's con "NA" en las columnas categóricas
datos[, nombres_categoricos] <- lapply(datos[, nombres_categoricos, drop = FALSE], function(x) ifelse(is.na(x), "NA", x))

#Reemplazar "NA" con 0 en columnas categóricas
datos[, nombres_categoricos] <- lapply(datos[, nombres_categoricos, drop = FALSE], function(x) replace(x, x == "NA", 0))

```

```{r showData withoutN Na}
no_null_counts <- colSums(!is.na(datos))
print(no_null_counts)
```

###Seleccion de las columnas 
```{r instalacionlibrerias}
install.packages("ggplot2")
install.packages("reshape2")
library(ggplot2)
library(reshape2)
```


```{r datosColumnas}
# Definir las columnas seleccionadas basadas en su correlación de Spearman > 0.6
selected_columns <- c("OverallQual", "YearBuilt", "ExterQual", "BsmtQual", "TotalBsmtSF", 
                      "GrLivArea", "FullBath", "KitchenQual", "GarageCars", "GarageArea")

# Seleccionar las columnas del dataframe
selected_predictors <- datos[selected_columns]

# Calcular la matriz de correlación
predictors_corr <- cor(selected_predictors, use = "complete.obs", method = "pearson")

# Transformar la matriz de correlación para la visualización
melted_corr <- melt(predictors_corr)

# Crear el mapa de calor, ajustar el tema y añadir los textos de correlación
ggplot(data = melted_corr, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +  # Dibuja los cuadros del mapa de calor
  geom_text(aes(label = sprintf("%.2f", value)), size = 3, color = "black") +  # Añade los valores de correlación
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Correlación de Pearson") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8),  # Reduce el tamaño del texto del eje x
        axis.text.y = element_text(size = 8)) +  # Reduce el tamaño del texto del eje y
  labs(x = "", y = "", title = "Mapa de Calor de Correlación") +
  coord_fixed(ratio = 1 / (length(selected_columns) / 5))  # Ajusta el tamaño de los cuadros

```
###Seleccion de los mejores datos en la correlacion
```{r MejoresDatos}


mejores_Datos <- datos %>% dplyr::select(OverallQual, YearBuilt,  KitchenQual, GarageArea, FullBath, GrLivArea, GarageCars, X1stFlrSF, FullBath, TotRmsAbvGrd, FireplaceQu, MasVnrArea)

head(mejores_Datos)

```

Estos seran los datos a utilzar en los distintos modelos ya que han sido los que mejor correlación poseen y poseen una buena correlacion de pearson

#Modelado 

###Regresion Lineal

```{r regresion lineal}
library(caTools)  # Para dividir los datos
library(MASS)     # Para AIC y BIC si es necesario

y <- datos$SalePrice
X <- scale(mejores_Datos)

# Convertir la matriz escalada de nuevo a un dataframe
X_df <- as.data.frame(X)

# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)  # Para reproducibilidad
split <- sample.split(y, SplitRatio = 0.8)
X_train <- X_df[split, ]
X_test <- X_df[!split, ]
y_train <- y[split]
y_test <- y[!split]

# Ajustar el modelo de regresión lineal
model <- lm(y_train ~ ., data = X_train)

# Realizar predicciones en el conjunto de prueba
y_pred <- predict(model, newdata = X_test)

# Calcular métricas de evaluación
explained_variance <- summary(model)$r.squared
mean_squared_error <- mean((y_test - y_pred)^2)
r2 <- summary(model)$r.squared
mean_absolute_error <- mean(abs(y_test - y_pred))
mse <- mean_squared_error
aic <- AIC(model)
bic <- BIC(model)

# Imprimir las métricas de evaluación
cat("Explained Variance:", explained_variance, "\n")
cat("Mean Squared Error:", mean_squared_error, "\n")
cat("R2:", r2, "\n")
cat("Mean Absolute Error:", mean_absolute_error, "\n")
cat("Mean Squared Error:", mse, "\n")
cat("AIC:", aic, "\n")
cat("BIC:", bic, "\n")


```

##Análisis residual

```{r analisisResiduales}
# Gráfico de dispersión de residuos
plot(residuos, type = "p", main = "Gráfico de Dispersión de Residuos",
     xlab = "Índice de Observación", ylab = "Residuos")
abline(h = 0, col = "red")  # Línea horizontal en 0 para referencia
```
```{r historesiduos}
# Histograma de los residuos
# Establecer límites para el eje x excluyendo el dato atípico
lim_x <- quantile(residuos, c(0.01, 0.99))

# Histograma de los residuos con límites en el eje x
hist(residuos, breaks = 30, xlim = lim_x, freq = FALSE,
     main = "Histograma de los Residuos con Curva Normal",
     xlab = "Residuos", col = "lightblue")

# Calcular la media y la desviación estándar de los residuos
media_residuos <- mean(residuos)
sd_residuos <- sd(residuos)

# Superponer una curva normal
curve(dnorm(x, mean = media_residuos, sd = sd_residuos), 
      col = "red", lwd = 2, add = TRUE, xlim = lim_x)

# Añadir leyenda
legend("topright", legend = c("Densidad Normal", "Residuos"), 
       col = c("red", "black"), lty = 1:1, cex = 0.8)

```


```{r qqgrafico}
# Gráfico Q-Q de los residuos
# Filtrar los residuos para excluir valores extremos
lim_qq <- quantile(residuos, c(0.01, 0.99))  # Establecer límites basados en cuantiles
residuos_filtrados <- residuos[residuos > lim_qq[1] & residuos < lim_qq[2]]

# Gráfico Q-Q de los residuos filtrados
qqnorm(residuos_filtrados, main = "Gráfico Q-Q de los Residuos (sin atípicos)")
qqline(residuos_filtrados, col = "red")  # Añadir línea Q-Q

```

```{r shapiroPrueba}
# Prueba de Shapiro-Wilk para normalidad de los residuos
shapiro.test(residuos)
```

Las distintas graficas nos muestran que los residuos siguen una distribucion normal pero al poseer un valor W bajo y un valor p extremadamente bajo sugiere que los residuos de tu modelo no se distribuyen normalmente. Esto puede ser un indicativo de varios problemas potenciales con el modelo y que poseemos algunos valores atípicos distorcionando así la distribución de los residuos

### Modelo Lasso
```{r LassoModelLibrarys}
install.packages("glmnet")
install.packages("Metrics")
library(glmnet)
library(Metrics)
```

```{r ModelLasso}
# Ajustar el modelo LASSO con validación cruzada
set.seed(42)  # Para reproducibilidad
cv_lasso <- cv.glmnet(x = X, y = y, alpha = 1, family = "gaussian")

# Ver el valor lambda que minimiza el error de validación cruzada
best_lambda <- cv_lasso$lambda.min
print(best_lambda)

# Crear el modelo LASSO usando el mejor lambda
lasso_model <- glmnet(x = X, y = y, alpha = 1, lambda = best_lambda, family = "gaussian")

# Ver los coeficientes del modelo
coef(lasso_model)
```
Los que poseen valores nulos no contribuyen en nada a la variable dependiente para poder predecirla por lo que FullBath y TotRmsAbvGrd  no son relevantes para el modelo en el contexto de las otras variables. La variable que mejor predice el valor de SalePrice es la OverallQuallya que posee el coeficiente con mayor valor.

```{r LassoModelComp}

explained_variance_lasso <- cor(y_test, y_pred_lasso)^2

# Asegurarse de que no haya valores negativos
if(any(y_test <= 0) | any(y_pred_lasso <= 0)){
  stop("MSLE no puede ser calculado para valores negativos o cero.")
}

mean_squared_log_error_lasso <- mean((log(y_pred_lasso + 1) - log(y_test + 1))^2)

# Realizar predicciones con el modelo LASSO
y_pred_lasso <- predict(lasso_model, newx = as.matrix(X_test), s = best_lambda, type = "response")

# Calcular el R2
r2_lasso <- cor(y_test, y_pred_lasso)^2

# Calcular el Mean Squared Error (MSE)
mse_lasso <- mse(y_test, y_pred_lasso)

# Calcular el Mean Absolute Error (MAE)
mae_lasso <- mae(y_test, y_pred_lasso)

# Calcular AIC (No está directamente disponible para modelos glmnet, así que se usa una aproximación)
n <- length(y_test)  # Número de observaciones en el conjunto de prueba
p <- sum(coef(lasso_model, s = best_lambda) != 0)  # Número de predictores seleccionados por LASSO
aic_lasso <- n * log(mse_lasso) + 2 * p

# Calcular BIC (Usando la misma aproximación)
bic_lasso <- n * log(mse_lasso) + log(n) * p

# Imprimir las métricas de evaluación
cat("Explained Variance LASSO:", explained_variance_lasso, "\n")
cat("Mean Squared Log Error (MSLE) LASSO:", mean_squared_log_error_lasso, "\n")
cat("R2 LASSO:", r2_lasso, "\n")
cat("Mean Squared Error (MSE) LASSO:", mse_lasso, "\n")
cat("Mean Absolute Error (MAE) LASSO:", mae_lasso, "\n")
cat("AIC LASSO:", aic_lasso, "\n")
cat("BIC LASSO:", bic_lasso, "\n")
```
##Análisis residual
```{r calculoResiduos}
# Realizar predicciones con el modelo LASSO
y_pred_lasso <- predict(lasso_model, newx = as.matrix(X_test), s = best_lambda, type = "response")

# Calcular los residuos
residuos <- y_test - y_pred_lasso
# Gráfico de dispersión de residuos
plot(residuos, type = "p", main = "Gráfico de Dispersión de Residuos LASSO",
     xlab = "Índice de Observación", ylab = "Residuos")
abline(h = 0, col = "red")  # Línea horizontal en 0 para referencia

```

```{r lassoHisto}
# Establecer límites para el eje x excluyendo el dato atípico
lim_x <- quantile(residuos, c(0.01, 0.99))

# Histograma de los residuos con límites en el eje x
hist(residuos, breaks = 30, xlim = lim_x, freq = FALSE,
     main = "Histograma de los Residuos LASSO con Curva Normal",
     xlab = "Residuos", col = "lightblue")

# Superponer una curva normal
media_residuos <- mean(residuos)
sd_residuos <- sd(residuos)
curve(dnorm(x, mean = media_residuos, sd = sd_residuos), 
      col = "red", lwd = 2, add = TRUE, xlim = lim_x)

# Añadir leyenda
legend("topright", legend = c("Densidad Normal", "Residuos LASSO"), 
       col = c("red", "black"), lty = 1:1, cex = 0.8)
```

```{r lasso qq}
# Filtrar los residuos para excluir valores extremos
lim_qq <- quantile(residuos, c(0.01, 0.99))
residuos_filtrados <- residuos[residuos > lim_qq[1] & residuos < lim_qq[2]]

# Gráfico Q-Q de los residuos filtrados
qqnorm(residuos_filtrados, main = "Gráfico Q-Q de los Residuos LASSO (sin atípicos)")
qqline(residuos_filtrados, col = "red")

```
```{r lassoShapiro}
# Prueba de Shapiro-Wilk para normalidad de los residuos

```
El coeficiente de determinación r^2 de 0.666 indica que el modelo puede explicar aproximadamente el 66.6% de la variabilidad en los datos, lo cual es un rendimiento razonablemente bueno. Sin embargo, una tercera parte de la variabilidad no está siendo capturada por el modelo.

El valor de la prueba de Shapiro-Wilk sugieren fuertemente que los residuos del modelo no siguen una distribución normal. Esta desviación de la normalidad, especialmente con un valor W relativamente bajo, indica que puede haber problemas con la especificación del modelo, como la omisión de variables importantes, o la presencia de valores atípicos que podrían estar distorsionando la distribución de los residuos.